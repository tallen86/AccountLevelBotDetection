{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.0 (default, Jun 28 2018, 08:04:48) [MSC v.1912 64 bit (AMD64)]\n",
      "0.20.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# CTRL + SHIFT + P => Run Code \n",
    "import sys\n",
    "print('Python', sys.version)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global ResultsCollection \n",
    "ResultsCollection = pd.DataFrame(columns=('Algorithm', 'FeatureSet', 'TestAcc', 'TestAUC'))\n",
    "\n",
    "global testSize\n",
    "testSize = 0.20\n",
    "\n",
    "# Create Folder to save too\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "date = datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"\\\\\"\n",
    "\n",
    "global path\n",
    "path = \"D:\\\\0_MyFiles\\\\0_Libraries\\\\Documents\\\\Education\\\\University\\\\Year 3\\\\FYP_Git\\\\ParamSet\\\\\" + str(date)\n",
    "\n",
    "import os\n",
    "#if not os.path.exists(path):\n",
    "#    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Set List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch for multiple feautre sets\n",
    "def getFeatureSet(number):\n",
    "    return {\n",
    "        1 : ['followers_count', 'friends_count', 'statuses_count', 'favourites_count', 'listed_count', 'verified', 'bot'],\n",
    "        2 : ['followers_count', 'friends_count', 'statuses_count', 'favourites_count', 'listed_count_binary', 'verified', \n",
    "             'name_binary','description_binary', 'screen_name_binary','bot'],\n",
    "        3 : ['followers_count', 'friends_count', 'statuses_count', 'favourites_count', 'listed_count', 'verified', \n",
    "             'name_binary','description_binarySTEM', 'screen_name_binary','bot'],        \n",
    "        99 : ['followers_count', 'friends_count', 'statuses_count', 'favourites_count', 'listed_count', 'verified', \n",
    "              'name', 'screen_name', 'description', 'bot'],\n",
    "    }[number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data from csv\n",
    "training_data = pd.read_csv('training_data.csv')\n",
    "t2 = pd.read_csv('genuine_accounts_users.csv')\n",
    "t3 = pd.read_csv('fake_followers_users.csv')\n",
    "training_data['description'].fillna(' ', inplace=True)\n",
    "\n",
    "features = getFeatureSet(99)\n",
    "\n",
    "t2['bot'] = 0\n",
    "t3['bot'] = 1\n",
    "\n",
    "t2 = t2[features]\n",
    "t3 = t3[features]\n",
    "training_data = training_data[features]\n",
    "\n",
    "new_data = t2.append(t3, ignore_index=True)\n",
    "training_data = new_data.append(training_data, ignore_index=True)\n",
    "\n",
    "training_data = training_data.sample(frac=1).reset_index(drop=True)\n",
    "training_data['description'].fillna(' ', inplace=True)\n",
    "training_data['verified'].fillna('0', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming applied to description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextDesc(desc):\n",
    "    try:\n",
    "        if isinstance(desc, float):\n",
    "            return ''\n",
    "        return desc\n",
    "    except Exception as error:\n",
    "        return ''\n",
    "    \n",
    "training_data['description'] = training_data.apply(lambda row: getTextDesc(row['description']), axis=1)\n",
    "\n",
    "def stemLine(sentence):\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    translator=sentence.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "    translator = translator.lower()\n",
    "    tokens = word_tokenize(translator)\n",
    "    final = [stemmer.stem(tagged_word) for tagged_word in tokens]\n",
    "    return \" \".join(final)\n",
    "\n",
    "training_data['descriptionStemmed'] = training_data['description'].apply(lambda row: stemLine(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary True/False Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary\n",
    "name_keywords = r'bot|b0t|papers'\n",
    "stemmedKeywords = r'bot|b0t|random|#botally|creat|thi|time|//|botal|pubm|made|im|gener|day|everi|paper|follow|tweet|word'\n",
    "keywords = r'bot|b0t|papers|#botally|follow|every|made|//|random|day|daily|tweet|tweets|made'\n",
    "\n",
    "training_data['name_binary'] = training_data.name.str.contains(keywords, case=False, na=False)\n",
    "training_data['screen_name_binary'] = training_data.screen_name.str.contains(keywords, case=False, na=False)\n",
    "\n",
    "training_data['description_binarySTEM'] = training_data.description.str.contains(stemmedKeywords, case=False, na=False)\n",
    "\n",
    "training_data['description_binary'] = training_data.description.str.contains(keywords, case=False, na=False)\n",
    "#training_data['status_binary'] = training_data.status.str.contains(keywords, case=False, na=False)\n",
    "\n",
    "training_data['listed_count_binary'] = (training_data.listed_count>20000)==False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "training_data.description.fillna(' ')\n",
    "training_data.screen_name.fillna(' ')\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "CountVec = vectorizer.fit_transform(training_data.description.values.astype('U')).toarray()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "CountVecStemmed = vectorizer.fit_transform(training_data.descriptionStemmed.values.astype('U')).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Classifier Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Features create the test and traing X and Y\n",
    "def initiateXY(features, testsize):\n",
    "    # set X to all data fields and Y to bot field\n",
    "    x = training_data[features].iloc[:, :-1] # x is all data\n",
    "    y = training_data[features].iloc[:, -1] # y is bot bool\n",
    "    return train_test_split(x, y, test_size=testsize, random_state=10)\n",
    "\n",
    "# Get accuracy of a classifer\n",
    "def get_results(classifer, x, y):\n",
    "    ypredict = classifer.predict(x) # Predict Y value for all of X\n",
    "    acc = accuracy_score(y, ypredict) # Find accuracy of prediction with the results 'Y'\n",
    "    return acc\n",
    "\n",
    "# Plot ROC Curve graph\n",
    "def getAUC(clf, xtest, ytest, xtrain, ytrain, runName, feauteSet):  \n",
    "    score_train = clf.predict_proba(xtrain)\n",
    "    score_test = clf.predict_proba(xtest)\n",
    "    \n",
    "    y_sTrain = []\n",
    "    y_sTest = []\n",
    "    \n",
    "    for i in range(len(score_train)):\n",
    "        y_sTrain.append(score_train[i][1])\n",
    "\n",
    "    for i in range(len(score_test)):\n",
    "        y_sTest.append(score_test[i][1])\n",
    "        \n",
    "    fpr_train, tpr_train, _ = roc_curve(ytrain, y_sTrain, pos_label=1)\n",
    "    fpr_test, tpr_test, _ = roc_curve(ytest, y_sTest, pos_label=1)\n",
    "    \n",
    "    return (auc(fpr_test, tpr_test))\n",
    "\n",
    "# Calculate and print a classifiers accuracy\n",
    "def testClassifer(classifier, xtrain, xtest, ytrain, ytest, printRoc, runName, feauteSet):\n",
    "    acc_train = get_results(classifier, xtrain, ytrain)\n",
    "    acc_test = get_results(classifier, xtest, ytest)\n",
    "    \n",
    "    if printRoc == True:\n",
    "        AUC = getAUC(classifier, xtest, ytest, xtrain, ytrain, runName, feauteSet)\n",
    "    \n",
    "    print('Training Accuracy:  ', acc_train)\n",
    "    print('Test Accuracy:  ', acc_test)\n",
    "    print('AUC:', AUC)\n",
    "    \n",
    "    return acc_test, AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "def run_RF(feauteSet, testsize, printRoc, runName):\n",
    "    features = getFeatureSet(feauteSet)\n",
    "    xtrain, xtest, ytrain, ytest = initiateXY(features, testsize)\n",
    "\n",
    "    lr = LogisticRegression(random_state=10, solver='lbfgs',multi_class='multinomial')\n",
    "    \n",
    "    param_grid = {'C': [0.00001,0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "\n",
    "    CV_rf = GridSearchCV(estimator=lr, param_grid=param_grid)  \n",
    "    CV_rf.fit(xtrain, ytrain)  \n",
    "    print(CV_rf.best_params_)\n",
    "    \n",
    "run_RF(3, testSize, True, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
